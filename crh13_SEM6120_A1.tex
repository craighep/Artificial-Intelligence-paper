
\documentclass[article]{IEEEtran}
\usepackage{graphicx}
 \usepackage{url}

\begin{document}

\title{Fundamentals of Artificial Intelligence Assignment 1- Ethical issues of AI}

\author{\IEEEauthorblockN{Craig Heptinstall}
\IEEEauthorblockA{Crh13- 110005643\\SEM6120\\
Institute of Computer Science\\
Aberystywth University}}

\maketitle

\begin{abstract}
The ethics of Artificial intelligence is an ever increasing debate amongst scientists and those that try to enforce new laws (e.g. privacy) or rights, with machines becoming more and more involved with the day-to-day practises and activities of people around the world. Though true AI (there is debate about that too) is something that may take many years to conceive, the ethics will always be an issue that will need addressing. So what is AI? Why are ethics important? What ethics are already considered today?
\end{abstract}

\section{Introduction}
Although this paper looks generally at ethics in Artificial intelligence, to understand the topic in more depth, ethics can be broken into two questions that can be asked for both humans and machines alike. Can the subject (person or machine) be ethical? And can the subject be effected by the ethics of others? The first of these questions looks at the responsibilities of AI, and whether AI should be used for such purposes as weaponry, or health care. The second question looks at AI rights, laws that could one day effect how they work, and if AI can even be considered to be under the same social circumstances as a person.

\subsection{What is Artificial Intelligence?}
Before answering questions about the ethics of AI, it is important to define to a certain extent what the term ‘Artificial intelligence’ means. To break this further, understanding the word intelligence can help define the greater meaning. Alan Turing \cite{Alan Turing website} breaks intelligence into five major components, all of which should be fulfilled in order to be classed as intelligent:
\begin{enumerate}
\item Learning- The simplest form of this is trial and error, with more complicated forms such as generalisation meaning the learner can perform better in situations not encountered before.
\item Reasoning- Using evidence from a set of given statements to deduct a conclusion.
\item Problem solving- Special and general-purpose methods exists, where the special means a method of solving the problem is tailor made, while the latter means the method can be applied to a larger pool of general problems.	
\item Perception- To be able to process and analyse scenes into objects, features and relationships.
\item Language- To use a system of signs, or sounds to communicate or send information to others. 
\end{enumerate}
Knowing the general requirements of intelligence, Artificial Intelligence should allow machines perform operations or actions that require the intelligence listed above in humans.

\subsection{Why Ethics are important}
In a world where humans are becoming more and more dependent on machines, the need for AI is exponentially increasing. Due to this circumstance, ensuring that any machines or computers used that are safety critical, are depended on (e.g. healthcare), or cases where sensible decisions are ethically correct is of a high importance. This relates back to the reasoning component of the AI definition. One example from the Cambridge Handbook of AI \cite{ethics important}, could be that in the near future where for instance a machine that decides  on mortgage decisions is found to be being unfairly handing out successful applications based on discriminative terms, who is to blame? Why is the machine coming to such results? It could be said that as long as humans are imperfect, so machines will be. 
Alongside these kind of ethics, there is also the other side to be considered, the ethical rights of the machines themselves. Though this topic requires more imagination about the future, machines that have feelings should still be considered. For instance, if a machine was working in bad conditions, or being treated badly, should they have rights?  

\subsection{AI ethics being considered today, and tomorrow}
Although laws and rules have been around for misuses of technology for some time now, no concrete laws regarding the use of Artificial Intelligence are under use at this time, meaning uses of AI for weaponry or wrongdoing is not currently monitored. Because at this time AI is not fully developed, and may have some time to go, creating laws that manage unethical behaviour might not fit well with future and more advanced AI. 
Aside from laws which are maintained by the courts, AI and machines used for public purposes are still judged by society, and general census around misusing AI can affect how they are used. Drones for example, which are now becoming more and more popular with the general public have meant they are used for many uses, from capturing images to performing deliveries. There are however circumstances where privacy is breached, or accidents from using autonomous drones have taken place. The use of Artificially Intelligent drones will be looked at in the following section of this paper.
Alongside current examples where ethics have had to been taken into careful consideration, fictional ethics and rules have been created, which have then become a part of current research. The Author and professor Isaac Asimov created three basic ‘laws of robotics’ (made famous by the fictional story of I, Robot) in \cite{laws} 1942 which were:
\begin{enumerate}
\item A robot may not injure a human being or, through inaction, allow a human being to come to harm.
\item A robot must obey orders given it by human beings except where such orders would conflict with the First Law.
\item A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. 
\end{enumerate}
Although fictional, the laws have been deeply discussed in current AI advances, such as in an edition of the IEEE Intelligent Systems \cite{ieeRobots}, where the laws were modified to try reflect todays current AI. Relating this back to current and future uses of intelligent machines, the three laws are not always a necessity to engineers, for instance military uses of autonomous vehicles designed to kill enemies would not have such laws built into their designs. 
Creating a standard applicable set of rules for future AI could be integral to ensuring that future technologies are morally and ethically correct.


\section{Recent research into Ethics of AI}
Stuff here, break it up.

\section{A critique of Ethics research}
Break this up.

\section{Overall findings and conclusion}

\begin{thebibliography}{9}

\bibitem{Alan Turing website} 
What is AI?, B.J. Copeland, 2000.
\\\texttt{\url{www.alanturing.net/turing_archive/pages/reference articles/what is ai.htmll}}

\bibitem{ethics important} 
Nick Bostrom and Eliezer Yudkowsky. 
\textit{The Ethics of Artificial Intelligence}. 
Cambridge Handbook of Artificial Intelligence, 2011.

\bibitem{Slate Technology news site} 
Robots Are People Too, J.F. Weaver 2014.
\\\texttt{\url{www.slate.com/articles/technology/future_tense/2014/07/ai_drones_ethics_and_laws_if_corporations_are_people_so_are_robots.single.html}}

\bibitem{laws} 
Isaac Asimov's "Three Laws of Robotics" , I. Asimov 1942.
\\\texttt{\url{http://www.auburn.edu/~vestmon/robotics.html}}

\bibitem{ieeRobots} 
Beyond Asmiov: The three laws of responsible robotics, R. Murphy, D. Woods, 2009.
\\\texttt{\url{http://www.computer.org/csdl/mags/ex/2009/04/mex2009040014-abs.html}}

\end{thebibliography}
\end{document}



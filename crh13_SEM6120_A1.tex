
\documentclass[article]{IEEEtran}
\usepackage{graphicx}
 \usepackage{url}
\setlength{\parskip}{0.5em}
\setlength{\parindent}{2em}

\begin{document}

\title{Fundamentals of Artificial Intelligence Assignment 1- Ethical issues of AI}

\author{\IEEEauthorblockN{Craig Heptinstall}
\IEEEauthorblockA{Crh13- 110005643\\SEM6120\\
Institute of Computer Science\\
Aberystywth University}}

\maketitle

\begin{abstract}
The ethics of Artificial intelligence is an ever increasing debate amongst scientists and those that try to enforce new laws (e.g. privacy) or rights, with machines becoming more and more involved with the day-to-day practises and activities of people around the world. Though true AI (there is debate about that too) is something that may take many years to conceive, the ethics will always be an issue that will need addressing. So what is AI? Why are ethics important? What ethics are already considered today?
\end{abstract}

\section{Introduction}
Although this paper looks generally at ethics in Artificial intelligence, to understand the topic in more depth, ethics can be broken into two questions that can be asked for both humans and machines alike. Can the subject (person or machine) be ethical? And can the subject be effected by the ethics of others? The first of these questions looks at the responsibilities of AI, and whether AI should be used for such purposes as weaponry, or health care. The second question looks at AI rights, laws that could one day effect how they work, and if AI can even be considered to be under the same social circumstances as a person. This paper looks at the general area of AI ethics, and uses sources from a number of journals and news articles to discuss current (less than five years) research, and provides a critique of each.

\subsection{What is Artificial Intelligence?}
Before answering questions about the ethics of AI, it is important to define to a certain extent what the term ‘Artificial intelligence’ means. To break this further, understanding the word intelligence can help define the greater meaning. Alan Turing \cite{Alan Turing website} breaks intelligence into five major components, all of which should be fulfilled in order to be classed as intelligent:
\begin{enumerate}
\item Learning- The simplest form of this is trial and error, with more complicated forms such as generalisation meaning the learner can perform better in situations not encountered before.
\item Reasoning- Using evidence from a set of given statements to deduct a conclusion.
\item Problem solving- Special and general-purpose methods exists, where the special means a method of solving the problem is tailor made, while the latter means the method can be applied to a larger pool of general problems.	
\item Perception- To be able to process and analyse scenes into objects, features and relationships.
\item Language- To use a system of signs, or sounds to communicate or send information to others. 
\end{enumerate}
Knowing the general requirements of intelligence, Artificial Intelligence should allow machines perform operations or actions that require the intelligence listed above in humans.

\subsection{Why Ethics are important}
In a world where humans are becoming more and more dependent on machines, the need for AI is exponentially increasing. Due to this circumstance, ensuring that any machines or computers used that are safety critical, are depended on (e.g. healthcare), or cases where sensible decisions are required should be ethically correct. This relates back to the reasoning component of the AI definition. \par
One example from the Cambridge Handbook of AI \cite{ethics important}, could be that in the near future where for instance a machine that decides  on mortgage decisions is found to be being unfairly handing out successful applications based on discriminative terms, who is to blame? Why is the machine coming to such results? It could be said that as long as humans are imperfect, so machines will be. 
Alongside these kind of ethics, there is also the other side to be considered, the ethical rights of the machines themselves. Though this topic requires more imagination about the future, machines that have feelings should still be considered. For instance, if a machine was working in bad conditions, or being treated badly, should they have rights?  

\subsection{AI ethics being considered today, and tomorrow}
Although laws and rules have been around for misuses of technology for some time now, no concrete laws regarding the use of Artificial Intelligence are under use at this time, meaning uses of AI for weaponry or wrongdoing is not currently monitored. Because at this time AI is not fully developed, and may have some time to go, creating laws that manage unethical behaviour might not fit well with future and more advanced AI. \par
Aside from laws which are maintained by the courts, AI and machines used for public purposes are still judged by society, and general census around misusing AI can affect how they are used. Drones for example, which are now becoming more and more popular with the general public have meant they are used for many uses, from capturing images to performing deliveries. There are however circumstances where privacy is breached, or accidents from using autonomous drones have taken place. The use of Artificially Intelligent drones will be looked at in the following section of this paper.\par
Alongside current examples where ethics have had to been taken into careful consideration, fictional ethics and rules have been created, which have then become a part of current research. The Author and professor Isaac Asimov created three basic ‘laws of robotics’ (made famous by the fictional story of I, Robot) in \cite{laws} 1942 which were:
\begin{enumerate}
\item A robot may not injure a human being or, through inaction, allow a human being to come to harm.
\item A robot must obey orders given it by human beings except where such orders would conflict with the First Law.
\item A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. 
\end{enumerate}
Although fictional, the laws have been deeply discussed in current AI advances, such as in an edition of the IEEE Intelligent Systems \cite{ieeRobots}, where the laws were modified to try reflect todays current AI.\par
 Relating this back to current and future uses of intelligent machines, the three laws are not always a necessity to engineers, for instance military uses of autonomous vehicles designed to kill enemies would not have such laws built into their designs. 
Creating a standard applicable set of rules for future AI could be integral to ensuring that future technologies are morally and ethically correct.

\section{Recent research into Ethics of AI}
Because ethics is such a broad topic, a great amount of research is already available. This part of the paper considers three papers from the past five years, looking at ethical uses of AI, through to considering the ethics of social and emotional AI. With each, a discussion of the research undertaken and findings will be referenced.

\subsection{The Ethics of Artificial Intelligence}
A paper already mentioned briefly earlier, this piece of research from the Cambridge Handbook of Artificial intelligence \cite{ethics important} looks at the ethical use of AI for a number of scenarios, discussing moral status of machines, the transparency of AI workings, and the ideas of superintelligence, referencing various examples of AI in good and bad circumstances. 
As discussed earlier, if AI is to be used more often for day-to-day activities, the ethical decisions taken by the intelligence must be justified by the engineers, creators of the intelligence, and the intelligence itself. The paper spoken about here starts by mentioning the main reasons for the need of ethical considerations when creating AI such as the AI uses its own advanced intelligence for good rather than ill. It then goes onto talking about the bank mortgage example, explaining how it could prove nearly impossible to understand how or why the AI algorithm could be judging applicants unfairly. \par
The paper points out that if AI was working for purposes such as this, it would enforce the need for complete transparency of the way the AI algorithm works. This would ensure that the system could be trusted more, and that finding out the reasons for failing behaviour or bad decisions are found out sooner. One counter argument that the paper does not mention is that if every AI algorithm was transparent, would that be safe for all uses? For example, where AI is used for controlling nuclear reactors, allowing humans to neglect and exploit the algorithms could result in dangerous circumstances. \par
This leads to another point made by the authors of the paper, who speak of the need for AI to learn, and basing as little knowledge as possible from information given by designers or engineers. The paper includes a good example of the case of Deep blue, where programmers sacrificed the ability to predict the AI’s next move, in order to get optimal results. This was shown when the system beat the world champion, Garry Kasparov. Although this method of creating AI can produce better results, it can be linked back to transparency, and getting the balance of predictability correct for today’s society.\par
Another safety critical point the paper raises is the design aspect of AI. AI should be able to for see consequences of actions. The author does point out issues with trying to do this though, such as that trying to find out consequences is none-local, meaning that consequences are more precise specifications, and though the system may be safe, the purpose of the system may never be fulfilled. Take one example, where in order to not lose a game of Tetris, a game-learning AI\cite{tetris} simply paused the game to avoid losing when the board filled up. On one hand, the ethical behaviour is something that could be strange to humans, but to the AI, it has acted in a way it thinks sensible.\par
To define the moral rights of the machines themselves, the paper then goes onto discuss what it means to have moral status, starting with an example of a rock, and how humans can subject it to any treatment without concern for the rock. It then goes onto to define why humans are subject to moral rights, while it is ‘widely agreed that current AI systems have no moral status’. The paper then goes onto explaining the basic requirements for an AI which would have moral status:
\begin{itemize}
\item Sentience- The machine would have to have the capacity to feel pain or suffer
\item Sapience- Having a higher intelligence such as self-awareness
\end{itemize}
So in theory, backed up by this paper, an AI could have some form of moral status if it could feel pain. The paper explains well here, stating that it is morally wrong to harm animals or other living things if it can feel pain. So if an AI could feel pain, this would be in effect affecting its moral rights. The following two papers in this article will go into further detail around pain, suffering and emotions within AI.\par
A part of the paper which deserves highlighting is the section about what would happen if a human was ‘uploaded’ to a machine, capturing all neurons and synaptic interconnections in the process. If the upload was successful, would the machine then be that person? And more importantly, would the AI then be sentient? If so, moral rights could then be in place for that AI. A lot or articles agree that once emotion and pain are in the AI after an upload, then it does have moral rights \cite{rightsTrue}, while others argue that if a machine became obsolete and not required \cite{rightsFalse}, it would be important that the machine did not have moral rights in order to dispose of it. \par
There are also other considerations within this paper, such as reproduction, would they reproduce? The paper explains the possibilities that the AI could simply clone itself, and each clone creating more clones until they run out of resources. In this case, the machines would have to be ethical in the way they chose to either remove old AI’s or manage the amount of children they have.\par
The final interesting but important point in the considerations of creating AI, is the speed at which this intelligence would operate. Due to the vast power of machines in today’s world, they can calculate solutions to vast problems at thousands of times the speed of a human. In one example, if the AI was one thousand times faster at perceiving the world than humans, one second of our time could correspond to seventeen minutes of AI time. In all that extra time, the AI could develop much faster than humans, until their idea of ethics could be considerably different to humans’. The paper uses one example where an AI is created with a fixed moral code of Ancient Greece. Would the ethics seem ethical today?  

\subsection{Emotion, Artificial Intelligence, and Ethics}

\subsection{Considering Social and Emotional Artificial Intelligence}

\section{Overall findings and conclusion}

\begin{thebibliography}{9}

\bibitem{Alan Turing website} 
What is AI?, B.J. Copeland, 2000.
\\\texttt{\url{www.alanturing.net/turing_archive/pages/reference articles/what is ai.htmll}}

\bibitem{ethics important} 
Nick Bostrom and Eliezer Yudkowsky. 
\textit{The Ethics of Artificial Intelligence}. 
Cambridge Handbook of Artificial Intelligence, 2011.

\bibitem{Slate Technology news site} 
Robots Are People Too, J.F. Weaver 2014.
\\\texttt{\url{www.slate.com/articles/technology/future_tense/2014/07/ai_drones_ethics_and_laws_if_corporations_are_people_so_are_robots.single.html}}

\bibitem{laws} 
Isaac Asimov's "Three Laws of Robotics" , I. Asimov 1942.
\\\texttt{\url{http://www.auburn.edu/~vestmon/robotics.html}}

\bibitem{ieeRobots} 
Beyond Asmiov: The three laws of responsible robotics, R. Murphy, D. Woods, 2009.
\\\texttt{\url{http://www.computer.org/csdl/mags/ex/2009/04/mex2009040014-abs.html}}

\bibitem{ethicsEmotion} 
Kevin LaGrandeur. 2010
\textit{Emotion, Artificial Intelligence, and Ethics }. 
New York Institute of Technology.

\bibitem{ethicsSocial}
M. Schroeder, G. McKeown. 2010
\textit{Considering Social and Emotiona lArtiﬁcial Intelligence}.

\bibitem{tetris}
This AI 'solves' Super Mario Bros. and other classic NES games. I. Steadman, 2013
\\\textit{\url{ http://www.wired.co.uk/news/archive/2013-04/12/super-mario-solved}}

\bibitem{rightsTrue}
When does Artificial Intelligence begin to have rights?. H. Edge, 2010
\\\textit{\url{ http://www.ethicsofthefuture.com/2010/09/at-what-point-does-artificial.html}}

\bibitem{rightsFalse}
Ethics of AI - Legal Rights. L. McGovern, 2008
\\\textit{\url{http://www.flickspin.com/en/artificial_intelligence/ethics_of_ai_legal_rights}}


\end{thebibliography}
\end{document}


